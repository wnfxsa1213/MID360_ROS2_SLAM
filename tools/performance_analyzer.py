#!/usr/bin/env python3
"""
MID360 SLAMç³»ç»Ÿæ€§èƒ½åˆ†æå·¥å…·
ä¸“é—¨ç”¨äºç³»ç»Ÿé›†æˆéªŒè¯å’Œæ€§èƒ½åŸºå‡†æµ‹è¯•
"""

import os
import sys
import time
import psutil
import subprocess
import threading
import signal
import json
from datetime import datetime
from dataclasses import dataclass, asdict
from typing import Dict, List, Optional, Tuple
import yaml

@dataclass
class SystemMetrics:
    """ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡"""
    timestamp: float
    cpu_percent: float
    memory_percent: float
    memory_mb: float
    network_sent_mbps: float
    network_recv_mbps: float
    disk_read_mbps: float
    disk_write_mbps: float
    process_count: int

@dataclass
class SlamMetrics:
    """SLAMç³»ç»ŸæŒ‡æ ‡"""
    timestamp: float
    fastlio_processing_time: float
    point_cloud_size: int
    imu_buffer_size: int
    lidar_buffer_size: int
    optimization_drift: float
    successful_optimizations: int
    failed_optimizations: int

@dataclass
class NetworkMetrics:
    """ç½‘ç»œæ€§èƒ½æŒ‡æ ‡"""
    timestamp: float
    latency_ms: float
    packet_loss_percent: float
    bandwidth_mbps: float
    jitter_ms: float

class PerformanceAnalyzer:
    """MID360 SLAMæ€§èƒ½åˆ†æå™¨"""

    def __init__(self, analysis_duration: int = 60):
        self.analysis_duration = analysis_duration
        self.system_metrics: List[SystemMetrics] = []
        self.slam_metrics: List[SlamMetrics] = []
        self.network_metrics: List[NetworkMetrics] = []
        self.monitoring = False
        self.start_time = None

        # ç½‘ç»œé…ç½®
        self.lidar_ip = "192.168.1.3"
        self.host_ip = "192.168.1.50"

        # æ€§èƒ½é˜ˆå€¼ï¼ˆåŸºäºç©¿è¶Šæœºè¦æ±‚ï¼‰
        self.performance_thresholds = {
            'max_processing_time_ms': 50,      # æœ€å¤§å¤„ç†å»¶è¿Ÿ50ms
            'target_processing_time_ms': 20,   # ç›®æ ‡å¤„ç†å»¶è¿Ÿ20ms
            'max_cpu_percent': 80,             # æœ€å¤§CPUä½¿ç”¨ç‡80%
            'max_memory_percent': 70,          # æœ€å¤§å†…å­˜ä½¿ç”¨ç‡70%
            'min_point_cloud_hz': 8,           # æœ€å°ç‚¹äº‘é¢‘ç‡8Hz
            'min_imu_hz': 800,                 # æœ€å°IMUé¢‘ç‡800Hz
            'max_network_latency_ms': 5,       # æœ€å¤§ç½‘ç»œå»¶è¿Ÿ5ms
            'max_packet_loss_percent': 0.1,    # æœ€å¤§ä¸¢åŒ…ç‡0.1%
        }

    def start_analysis(self):
        """å¼€å§‹æ€§èƒ½åˆ†æ"""
        print(f"ğŸ” å¼€å§‹MID360 SLAMç³»ç»Ÿæ€§èƒ½åˆ†æ (æŒç»­æ—¶é—´: {self.analysis_duration}ç§’)")
        print("="*60)

        self.monitoring = True
        self.start_time = time.time()

        # å¯åŠ¨ç›‘æ§çº¿ç¨‹
        threads = [
            threading.Thread(target=self._monitor_system_metrics, daemon=True),
            threading.Thread(target=self._monitor_slam_metrics, daemon=True),
            threading.Thread(target=self._monitor_network_metrics, daemon=True)
        ]

        for thread in threads:
            thread.start()

        # å®æ—¶æ˜¾ç¤ºåˆ†æè¿›åº¦
        self._display_realtime_analysis()

        # ç­‰å¾…åˆ†æå®Œæˆ
        time.sleep(max(0, self.analysis_duration - (time.time() - self.start_time)))
        self.monitoring = False

        # ç­‰å¾…çº¿ç¨‹ç»“æŸ
        for thread in threads:
            thread.join(timeout=1)

        return self._generate_analysis_report()

    def _monitor_system_metrics(self):
        """ç›‘æ§ç³»ç»Ÿèµ„æºæŒ‡æ ‡"""
        last_net_io = psutil.net_io_counters()
        last_disk_io = psutil.disk_io_counters()
        last_time = time.time()

        while self.monitoring:
            try:
                current_time = time.time()

                # ç½‘ç»œIOè®¡ç®—
                current_net_io = psutil.net_io_counters()
                net_sent_mbps = (current_net_io.bytes_sent - last_net_io.bytes_sent) / (current_time - last_time) / 1024 / 1024
                net_recv_mbps = (current_net_io.bytes_recv - last_net_io.bytes_recv) / (current_time - last_time) / 1024 / 1024

                # ç£ç›˜IOè®¡ç®—
                current_disk_io = psutil.disk_io_counters()
                disk_read_mbps = (current_disk_io.read_bytes - last_disk_io.read_bytes) / (current_time - last_time) / 1024 / 1024
                disk_write_mbps = (current_disk_io.write_bytes - last_disk_io.write_bytes) / (current_time - last_time) / 1024 / 1024

                # æ”¶é›†ç³»ç»ŸæŒ‡æ ‡
                metrics = SystemMetrics(
                    timestamp=current_time,
                    cpu_percent=psutil.cpu_percent(),
                    memory_percent=psutil.virtual_memory().percent,
                    memory_mb=psutil.virtual_memory().used / 1024 / 1024,
                    network_sent_mbps=net_sent_mbps,
                    network_recv_mbps=net_recv_mbps,
                    disk_read_mbps=disk_read_mbps,
                    disk_write_mbps=disk_write_mbps,
                    process_count=len(psutil.pids())
                )

                self.system_metrics.append(metrics)

                last_net_io = current_net_io
                last_disk_io = current_disk_io
                last_time = current_time

                time.sleep(1)

            except Exception as e:
                print(f"ç³»ç»Ÿç›‘æ§é”™è¯¯: {e}")
                time.sleep(1)

    def _monitor_slam_metrics(self):
        """ç›‘æ§SLAMæ€§èƒ½æŒ‡æ ‡"""
        while self.monitoring:
            try:
                # å°è¯•ä»ROS2è¯é¢˜è·å–æ€§èƒ½æŒ‡æ ‡
                fastlio_metrics = self._get_fastlio_metrics()
                coordinator_metrics = self._get_coordinator_metrics()

                if fastlio_metrics or coordinator_metrics:
                    metrics = SlamMetrics(
                        timestamp=time.time(),
                        fastlio_processing_time=fastlio_metrics.get('processing_time', 0),
                        point_cloud_size=fastlio_metrics.get('point_count', 0),
                        imu_buffer_size=fastlio_metrics.get('imu_buffer_size', 0),
                        lidar_buffer_size=fastlio_metrics.get('lidar_buffer_size', 0),
                        optimization_drift=coordinator_metrics.get('drift', 0),
                        successful_optimizations=coordinator_metrics.get('successful', 0),
                        failed_optimizations=coordinator_metrics.get('failed', 0)
                    )
                    self.slam_metrics.append(metrics)

                time.sleep(0.5)  # 2Hzç›‘æ§é¢‘ç‡

            except Exception as e:
                print(f"SLAMç›‘æ§é”™è¯¯: {e}")
                time.sleep(1)

    def _monitor_network_metrics(self):
        """ç›‘æ§ç½‘ç»œæ€§èƒ½æŒ‡æ ‡"""
        while self.monitoring:
            try:
                # Pingæµ‹è¯•å»¶è¿Ÿ
                latency = self._measure_network_latency()

                # ç½‘ç»œå¸¦å®½æµ‹è¯•ï¼ˆç®€åŒ–ç‰ˆï¼‰
                bandwidth = self._estimate_network_bandwidth()

                metrics = NetworkMetrics(
                    timestamp=time.time(),
                    latency_ms=latency,
                    packet_loss_percent=0.0,  # ç®€åŒ–å®ç°
                    bandwidth_mbps=bandwidth,
                    jitter_ms=0.0  # ç®€åŒ–å®ç°
                )

                self.network_metrics.append(metrics)
                time.sleep(2)  # 0.5Hzç›‘æ§é¢‘ç‡

            except Exception as e:
                print(f"ç½‘ç»œç›‘æ§é”™è¯¯: {e}")
                time.sleep(2)

    def _get_fastlio_metrics(self) -> Dict:
        """è·å–FASTLIO2æ€§èƒ½æŒ‡æ ‡"""
        try:
            # ä½¿ç”¨ros2 topic echoè·å–æ€§èƒ½æ•°æ®
            result = subprocess.run([
                'timeout', '1s', 'ros2', 'topic', 'echo',
                '/fastlio2/performance_metrics', '--once'
            ], capture_output=True, text=True, timeout=2)

            if result.returncode == 0:
                # è§£æè¾“å‡ºæ•°æ®
                lines = result.stdout.strip().split('\n')
                data_line = None
                for line in lines:
                    if 'data:' in line:
                        data_line = line
                        break

                if data_line:
                    # æå–æ•°ç»„æ•°æ® [processing_time, point_count, imu_buffer, lidar_buffer]
                    data_str = data_line.split('data:')[1].strip()
                    data_str = data_str.strip('[]')
                    values = [float(x.strip()) for x in data_str.split(',')]

                    return {
                        'processing_time': values[0] if len(values) > 0 else 0,
                        'point_count': int(values[1]) if len(values) > 1 else 0,
                        'imu_buffer_size': int(values[2]) if len(values) > 2 else 0,
                        'lidar_buffer_size': int(values[3]) if len(values) > 3 else 0
                    }
        except:
            pass
        return {}

    def _get_coordinator_metrics(self) -> Dict:
        """è·å–åè°ƒå™¨æ€§èƒ½æŒ‡æ ‡"""
        try:
            result = subprocess.run([
                'timeout', '1s', 'ros2', 'topic', 'echo',
                '/coordinator/metrics', '--once'
            ], capture_output=True, text=True, timeout=2)

            if result.returncode == 0:
                lines = result.stdout.strip().split('\n')
                data_line = None
                for line in lines:
                    if 'data:' in line:
                        data_line = line
                        break

                if data_line:
                    data_str = data_line.split('data:')[1].strip()
                    data_str = data_str.strip('[]')
                    values = [float(x.strip()) for x in data_str.split(',')]

                    return {
                        'drift': values[0] if len(values) > 0 else 0,
                        'score': values[1] if len(values) > 1 else 0,
                        'successful': int(values[2]) if len(values) > 2 else 0,
                        'failed': int(values[3]) if len(values) > 3 else 0
                    }
        except:
            pass
        return {}

    def _measure_network_latency(self) -> float:
        """æµ‹é‡ç½‘ç»œå»¶è¿Ÿ"""
        try:
            result = subprocess.run([
                'ping', '-c', '1', '-W', '1000', self.lidar_ip
            ], capture_output=True, text=True)

            if result.returncode == 0:
                for line in result.stdout.split('\n'):
                    if 'time=' in line:
                        time_str = line.split('time=')[1].split()[0]
                        return float(time_str)
        except:
            pass
        return 999.0  # è¶…æ—¶æˆ–é”™è¯¯

    def _estimate_network_bandwidth(self) -> float:
        """ä¼°ç®—ç½‘ç»œå¸¦å®½"""
        # ç®€åŒ–å®ç°ï¼šåŸºäºç½‘ç»œæ¥å£ç»Ÿè®¡
        try:
            net_io = psutil.net_io_counters()
            # è¿”å›ä¸€ä¸ªä¼°ç®—å€¼ï¼Œå®é™…åº”è¯¥è¿›è¡Œå¸¦å®½æµ‹è¯•
            return 100.0  # å‡è®¾100Mbps
        except:
            return 0.0

    def _display_realtime_analysis(self):
        """å®æ—¶æ˜¾ç¤ºåˆ†æè¿›åº¦"""
        while self.monitoring and (time.time() - self.start_time) < self.analysis_duration:
            try:
                elapsed = time.time() - self.start_time
                remaining = max(0, self.analysis_duration - elapsed)

                # è·å–æœ€æ–°æŒ‡æ ‡
                latest_system = self.system_metrics[-1] if self.system_metrics else None
                latest_slam = self.slam_metrics[-1] if self.slam_metrics else None
                latest_network = self.network_metrics[-1] if self.network_metrics else None

                # æ¸…å±å¹¶æ˜¾ç¤ºå®æ—¶æ•°æ®
                os.system('clear')
                print(f"ğŸ” MID360 SLAMç³»ç»Ÿæ€§èƒ½åˆ†æè¿›è¡Œä¸­ ({elapsed:.1f}/{self.analysis_duration}s)")
                print("="*60)

                if latest_system:
                    cpu_status = "âœ…" if latest_system.cpu_percent < 80 else "âš ï¸"
                    mem_status = "âœ…" if latest_system.memory_percent < 70 else "âš ï¸"
                    print(f"{cpu_status} CPUä½¿ç”¨ç‡: {latest_system.cpu_percent:.1f}%")
                    print(f"{mem_status} å†…å­˜ä½¿ç”¨ç‡: {latest_system.memory_percent:.1f}% ({latest_system.memory_mb:.0f}MB)")
                    print(f"ğŸ“¡ ç½‘ç»œ: â†‘{latest_system.network_sent_mbps:.2f} â†“{latest_system.network_recv_mbps:.2f} MB/s")

                if latest_slam:
                    proc_status = "âœ…" if latest_slam.fastlio_processing_time < 50 else "âš ï¸"
                    print(f"{proc_status} SLAMå¤„ç†æ—¶é—´: {latest_slam.fastlio_processing_time:.1f}ms")
                    print(f"ğŸ“Š ç‚¹äº‘å¤§å°: {latest_slam.point_cloud_size}")
                    print(f"ğŸ“ˆ ç¼“å†²åŒº: IMU({latest_slam.imu_buffer_size}) LiDAR({latest_slam.lidar_buffer_size})")

                if latest_network:
                    net_status = "âœ…" if latest_network.latency_ms < 10 else "âš ï¸"
                    print(f"{net_status} ç½‘ç»œå»¶è¿Ÿ: {latest_network.latency_ms:.1f}ms")

                print(f"\nâ±ï¸  å‰©ä½™æ—¶é—´: {remaining:.1f}ç§’")
                print("æŒ‰Ctrl+Cæå‰ç»“æŸåˆ†æ...")

                time.sleep(2)

            except KeyboardInterrupt:
                print("\n\nç”¨æˆ·ä¸­æ–­åˆ†æ...")
                self.monitoring = False
                break
            except Exception as e:
                print(f"æ˜¾ç¤ºé”™è¯¯: {e}")
                time.sleep(1)

    def _generate_analysis_report(self) -> Dict:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        print("\n\n" + "="*60)
        print("ğŸ“Š ç”Ÿæˆæ€§èƒ½åˆ†ææŠ¥å‘Š...")

        report = {
            'analysis_info': {
                'duration_seconds': self.analysis_duration,
                'start_time': datetime.fromtimestamp(self.start_time).isoformat(),
                'end_time': datetime.now().isoformat(),
                'samples_collected': {
                    'system_metrics': len(self.system_metrics),
                    'slam_metrics': len(self.slam_metrics),
                    'network_metrics': len(self.network_metrics)
                }
            },
            'system_performance': self._analyze_system_performance(),
            'slam_performance': self._analyze_slam_performance(),
            'network_performance': self._analyze_network_performance(),
            'integration_quality': self._analyze_integration_quality(),
            'recommendations': self._generate_recommendations()
        }

        return report

    def _analyze_system_performance(self) -> Dict:
        """åˆ†æç³»ç»Ÿæ€§èƒ½"""
        if not self.system_metrics:
            return {'status': 'no_data'}

        cpu_values = [m.cpu_percent for m in self.system_metrics]
        memory_values = [m.memory_percent for m in self.system_metrics]

        return {
            'cpu_utilization': {
                'average': sum(cpu_values) / len(cpu_values),
                'maximum': max(cpu_values),
                'minimum': min(cpu_values),
                'above_threshold_percent': len([x for x in cpu_values if x > 80]) / len(cpu_values) * 100
            },
            'memory_utilization': {
                'average': sum(memory_values) / len(memory_values),
                'maximum': max(memory_values),
                'minimum': min(memory_values),
                'above_threshold_percent': len([x for x in memory_values if x > 70]) / len(memory_values) * 100
            },
            'status': 'excellent' if max(cpu_values) < 60 and max(memory_values) < 50 else
                     'good' if max(cpu_values) < 80 and max(memory_values) < 70 else 'needs_optimization'
        }

    def _analyze_slam_performance(self) -> Dict:
        """åˆ†æSLAMæ€§èƒ½"""
        if not self.slam_metrics:
            return {'status': 'no_data'}

        processing_times = [m.fastlio_processing_time for m in self.slam_metrics if m.fastlio_processing_time > 0]

        if not processing_times:
            return {'status': 'insufficient_data'}

        avg_processing_time = sum(processing_times) / len(processing_times)
        max_processing_time = max(processing_times)

        return {
            'processing_performance': {
                'average_time_ms': avg_processing_time,
                'maximum_time_ms': max_processing_time,
                'realtime_capability': avg_processing_time < 50,
                'target_performance': avg_processing_time < 20
            },
            'data_flow': {
                'average_point_cloud_size': sum([m.point_cloud_size for m in self.slam_metrics]) / len(self.slam_metrics),
                'buffer_health': 'good'  # ç®€åŒ–è¯„ä¼°
            },
            'status': 'excellent' if avg_processing_time < 20 else
                     'good' if avg_processing_time < 50 else 'needs_optimization'
        }

    def _analyze_network_performance(self) -> Dict:
        """åˆ†æç½‘ç»œæ€§èƒ½"""
        if not self.network_metrics:
            return {'status': 'no_data'}

        latencies = [m.latency_ms for m in self.network_metrics if m.latency_ms < 999]

        if not latencies:
            return {'status': 'connection_issues'}

        avg_latency = sum(latencies) / len(latencies)

        return {
            'latency_analysis': {
                'average_ms': avg_latency,
                'maximum_ms': max(latencies),
                'minimum_ms': min(latencies)
            },
            'status': 'excellent' if avg_latency < 5 else
                     'good' if avg_latency < 10 else 'needs_optimization'
        }

    def _analyze_integration_quality(self) -> Dict:
        """åˆ†æç³»ç»Ÿé›†æˆè´¨é‡"""
        # åŸºäºæ•°æ®å¯ç”¨æ€§å’Œä¸€è‡´æ€§è¯„ä¼°é›†æˆè´¨é‡
        data_sources = {
            'system_monitoring': len(self.system_metrics) > 0,
            'slam_monitoring': len(self.slam_metrics) > 0,
            'network_monitoring': len(self.network_metrics) > 0
        }

        integration_score = sum(data_sources.values()) / len(data_sources) * 100

        return {
            'data_sources': data_sources,
            'integration_score': integration_score,
            'component_communication': 'functional' if integration_score > 60 else 'limited',
            'status': 'excellent' if integration_score > 80 else
                     'good' if integration_score > 60 else 'needs_improvement'
        }

    def _generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []

        # åŸºäºåˆ†æç»“æœç”Ÿæˆå»ºè®®
        if self.system_metrics:
            avg_cpu = sum([m.cpu_percent for m in self.system_metrics]) / len(self.system_metrics)
            avg_memory = sum([m.memory_percent for m in self.system_metrics]) / len(self.system_metrics)

            if avg_cpu > 70:
                recommendations.append("CPUä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®ä¼˜åŒ–ç®—æ³•æˆ–å‡å°‘å¯è§†åŒ–é¢‘ç‡")
            if avg_memory > 60:
                recommendations.append("å†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®æ£€æŸ¥å†…å­˜æ³„æ¼å’Œç¼“å†²åŒºå¤§å°")

        if self.slam_metrics:
            processing_times = [m.fastlio_processing_time for m in self.slam_metrics if m.fastlio_processing_time > 0]
            if processing_times:
                avg_time = sum(processing_times) / len(processing_times)
                if avg_time > 30:
                    recommendations.append("SLAMå¤„ç†æ—¶é—´è¶…å‡ºç›®æ ‡ï¼Œå»ºè®®ä¼˜åŒ–ç‚¹äº‘é™é‡‡æ ·å’ŒåŒ¹é…ç®—æ³•")

        if not recommendations:
            recommendations.append("ç³»ç»Ÿæ€§èƒ½è¡¨ç°è‰¯å¥½ï¼Œå»ºè®®ç»§ç»­ç›‘æ§é•¿æœŸç¨³å®šæ€§")

        return recommendations

    def save_report(self, report: Dict, output_path: str):
        """ä¿å­˜åˆ†ææŠ¥å‘Š"""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        print(f"ğŸ“„ åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {output_path}")

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='MID360 SLAMç³»ç»Ÿæ€§èƒ½åˆ†æå·¥å…·')
    parser.add_argument('--duration', '-d', type=int, default=60,
                       help='åˆ†ææŒç»­æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤60ç§’')
    parser.add_argument('--output', '-o', type=str,
                       default='performance_analysis_report.json',
                       help='è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--verbose', '-v', action='store_true',
                       help='è¯¦ç»†è¾“å‡ºæ¨¡å¼')

    args = parser.parse_args()

    # æ£€æŸ¥ROS2ç¯å¢ƒ
    try:
        result = subprocess.run(['ros2', 'node', 'list'],
                              capture_output=True, text=True, timeout=5)
        if result.returncode != 0:
            print("âŒ ROS2ç¯å¢ƒæœªæ­£ç¡®é…ç½®æˆ–SLAMç³»ç»Ÿæœªè¿è¡Œ")
            print("è¯·å…ˆå¯åŠ¨SLAMç³»ç»Ÿ: ./tools/slam_tools.sh start")
            sys.exit(1)
    except:
        print("âŒ æ— æ³•è®¿é—®ROS2ç¯å¢ƒ")
        sys.exit(1)

    # å¼€å§‹æ€§èƒ½åˆ†æ
    analyzer = PerformanceAnalyzer(analysis_duration=args.duration)

    try:
        report = analyzer.start_analysis()

        # ä¿å­˜æŠ¥å‘Š
        analyzer.save_report(report, args.output)

        # æ˜¾ç¤ºæ‘˜è¦
        print("\n" + "="*60)
        print("ğŸ“Š æ€§èƒ½åˆ†ææ‘˜è¦")
        print("="*60)

        if 'system_performance' in report:
            sys_perf = report['system_performance']
            if 'status' in sys_perf:
                print(f"ğŸ–¥ï¸  ç³»ç»Ÿæ€§èƒ½: {sys_perf['status']}")

        if 'slam_performance' in report:
            slam_perf = report['slam_performance']
            if 'status' in slam_perf:
                print(f"ğŸ¤– SLAMæ€§èƒ½: {slam_perf['status']}")

        if 'network_performance' in report:
            net_perf = report['network_performance']
            if 'status' in net_perf:
                print(f"ğŸ“¡ ç½‘ç»œæ€§èƒ½: {net_perf['status']}")

        if 'integration_quality' in report:
            int_quality = report['integration_quality']
            if 'status' in int_quality:
                print(f"ğŸ”— é›†æˆè´¨é‡: {int_quality['status']}")

        if 'recommendations' in report:
            print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
            for i, rec in enumerate(report['recommendations'], 1):
                print(f"   {i}. {rec}")

        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Š: {args.output}")

    except KeyboardInterrupt:
        print("\n\nåˆ†æè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()