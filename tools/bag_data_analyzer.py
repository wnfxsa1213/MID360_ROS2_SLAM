#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sqlite3
import numpy as np
import matplotlib.pyplot as plt
from collections import defaultdict
import argparse
import sys
import json
from pathlib import Path

def analyze_bag_data(bag_path):
    """åˆ†æbagæ–‡ä»¶æ•°æ®è´¨é‡"""

    print(f"ğŸ” åˆ†æbagæ–‡ä»¶: {bag_path}")

    # è¿æ¥sqliteæ•°æ®åº“
    conn = sqlite3.connect(bag_path)
    cursor = conn.cursor()

    # è·å–æ‰€æœ‰è¯é¢˜å’Œæ¶ˆæ¯
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
    tables = cursor.fetchall()

    # è·å–topicsè¡¨
    cursor.execute("SELECT id, name, type FROM topics")
    topics = {row[0]: {'name': row[1], 'type': row[2]} for row in cursor.fetchall()}

    analysis_results = {}

    # åˆ†ææ¯ä¸ªè¯é¢˜
    for topic_id, topic_info in topics.items():
        topic_name = topic_info['name']
        print(f"\nğŸ“Š åˆ†æè¯é¢˜: {topic_name}")

        # è·å–æ¶ˆæ¯æ—¶é—´æˆ³
        cursor.execute("SELECT timestamp FROM messages WHERE topic_id = ? ORDER BY timestamp", (topic_id,))
        timestamps = [row[0] for row in cursor.fetchall()]

        if not timestamps:
            continue

        # è½¬æ¢ä¸ºç§’
        timestamps_sec = np.array(timestamps) / 1e9

        # è®¡ç®—æ—¶é—´é—´éš”
        if len(timestamps_sec) > 1:
            intervals = np.diff(timestamps_sec)

            analysis_results[topic_name] = {
                'message_count': int(len(timestamps)),
                'duration': float(timestamps_sec[-1] - timestamps_sec[0]),
                'avg_frequency': float(len(timestamps) / (timestamps_sec[-1] - timestamps_sec[0]) if len(timestamps) > 1 else 0),
                'avg_interval': float(np.mean(intervals)),
                'std_interval': float(np.std(intervals)),
                'min_interval': float(np.min(intervals)),
                'max_interval': float(np.max(intervals)),
                'interval_outliers': int(np.sum(intervals > (np.mean(intervals) + 3 * np.std(intervals))))
            }

            # æ£€æŸ¥å¼‚å¸¸é—´éš”
            outlier_threshold = np.mean(intervals) + 3 * np.std(intervals)
            outliers = intervals > outlier_threshold

            if np.any(outliers):
                print(f"  âš ï¸  å‘ç° {np.sum(outliers)} ä¸ªå¼‚å¸¸æ—¶é—´é—´éš”")
                print(f"      æœ€å¤§é—´éš”: {np.max(intervals):.3f}s")
                print(f"      å¼‚å¸¸é˜ˆå€¼: {outlier_threshold:.3f}s")

            print(f"  ğŸ“ˆ é¢‘ç‡: {analysis_results[topic_name]['avg_frequency']:.1f} Hz")
            print(f"  â±ï¸  é—´éš”: {analysis_results[topic_name]['avg_interval']*1000:.1f}ms (Â±{analysis_results[topic_name]['std_interval']*1000:.1f}ms)")

    conn.close()

    # ç”ŸæˆæŠ¥å‘Š
    generate_report(analysis_results, bag_path)

    return analysis_results

def generate_report(results, bag_path):
    """ç”Ÿæˆæ•°æ®è´¨é‡æŠ¥å‘Š"""

    report = {
        'bag_file': str(bag_path),
        'analysis_timestamp': str(np.datetime64('now')),
        'topics': results
    }

    # æ£€æŸ¥é—®é¢˜
    issues = []

    for topic_name, data in results.items():
        if '/imu' in topic_name:
            # IMUåº”è¯¥æ˜¯200Hz
            if data['avg_frequency'] < 180:
                issues.append(f"IMUé¢‘ç‡è¿‡ä½: {data['avg_frequency']:.1f}Hz < 180Hz")
            if data['std_interval'] > 0.01:  # 10ms
                issues.append(f"IMUæ—¶é—´æŠ–åŠ¨è¿‡å¤§: {data['std_interval']*1000:.1f}ms")

        elif '/lidar' in topic_name:
            # LiDARåº”è¯¥æ˜¯10Hz
            if data['avg_frequency'] < 8:
                issues.append(f"LiDARé¢‘ç‡è¿‡ä½: {data['avg_frequency']:.1f}Hz < 8Hz")
            if data['std_interval'] > 0.05:  # 50ms
                issues.append(f"LiDARæ—¶é—´æŠ–åŠ¨è¿‡å¤§: {data['std_interval']*1000:.1f}ms")

        elif '/lio_odom' in topic_name:
            # é‡Œç¨‹è®¡åº”è¯¥æ˜¯10Hz
            if data['avg_frequency'] < 8:
                issues.append(f"é‡Œç¨‹è®¡é¢‘ç‡è¿‡ä½: {data['avg_frequency']:.1f}Hz < 8Hz")

        if data['interval_outliers'] > 0:
            issues.append(f"{topic_name}: {data['interval_outliers']} ä¸ªå¼‚å¸¸æ—¶é—´é—´éš”")

    report['issues'] = issues

    # ä¿å­˜æŠ¥å‘Š
    report_path = Path('bag_analysis_report.json')
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ“‹ æ•°æ®è´¨é‡æŠ¥å‘Š:")
    print(f"   ğŸ“„ å·²ä¿å­˜åˆ°: {report_path}")

    if issues:
        print(f"\nğŸš¨ å‘ç° {len(issues)} ä¸ªé—®é¢˜:")
        for i, issue in enumerate(issues, 1):
            print(f"   {i}. {issue}")
    else:
        print("\nâœ… æ•°æ®è´¨é‡è‰¯å¥½ï¼Œæœªå‘ç°æ˜æ˜¾é—®é¢˜")

def analyze_imu_data(bag_path):
    """æ·±åº¦åˆ†æIMUæ•°æ®"""

    print(f"\nğŸ”¬ æ·±åº¦åˆ†æIMUæ•°æ®...")

    # è¿™é‡Œéœ€è¦rosbag2_pyåº“æ¥è§£ææ¶ˆæ¯å†…å®¹
    # ç”±äºç¯å¢ƒé™åˆ¶ï¼Œæˆ‘ä»¬å…ˆè¿”å›åŸºæœ¬åˆ†æ
    print("   ğŸ“Š IMUæ•°æ®è¯¦ç»†åˆ†æéœ€è¦rosbag2_pyåº“æ”¯æŒ")
    print("   ğŸ’¡ å»ºè®®è¿è¡Œ: pip install rosbag2_py")

def main():
    parser = argparse.ArgumentParser(description='åˆ†æROS2 bagæ–‡ä»¶æ•°æ®è´¨é‡')
    parser.add_argument('bag_path', help='bagæ–‡ä»¶è·¯å¾„(.db3)')
    parser.add_argument('--detailed-imu', action='store_true', help='è¯¦ç»†åˆ†æIMUæ•°æ®')

    args = parser.parse_args()

    bag_path = Path(args.bag_path)
    if not bag_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {bag_path}")
        sys.exit(1)

    # åˆ†ææ•°æ®è´¨é‡
    results = analyze_bag_data(bag_path)

    if args.detailed_imu:
        analyze_imu_data(bag_path)

if __name__ == '__main__':
    main()