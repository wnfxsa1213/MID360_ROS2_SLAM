# æµ‹è¯•ä¸éªŒè¯æŒ‡å—

## æ¦‚è¿°

æœ¬æŒ‡å—æä¾›ä¸‰å¤§åŠŸèƒ½å¢å¼ºçš„å…¨é¢æµ‹è¯•ä¸éªŒè¯ç­–ç•¥ï¼Œç¡®ä¿åŠ¨æ€å¯¹è±¡å¤„ç†ã€PGOå›ç¯æ£€æµ‹å’ŒHBAå®æ—¶ä¼˜åŒ–åŠŸèƒ½çš„æ­£ç¡®æ€§ã€æ€§èƒ½å’Œå¯é æ€§ã€‚

## æµ‹è¯•æ¶æ„

### æµ‹è¯•åˆ†ç±»

```
æµ‹è¯•é‡‘å­—å¡”ç»“æ„:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           E2E Tests (å°‘é‡)            â”‚  â† ç«¯åˆ°ç«¯ç³»ç»Ÿæµ‹è¯•
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚        Integration Tests (ä¸­ç­‰)       â”‚  â† ç»„ä»¶é›†æˆæµ‹è¯•
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚          Unit Tests (å¤§é‡)           â”‚  â† å•å…ƒæµ‹è¯•
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æµ‹è¯•ç¯å¢ƒ

1. **å¼€å‘ç¯å¢ƒ**: å•å…ƒæµ‹è¯•å’Œå¿«é€ŸéªŒè¯
2. **é›†æˆç¯å¢ƒ**: ç»„ä»¶é›†æˆå’Œç³»ç»Ÿæµ‹è¯•
3. **æ€§èƒ½ç¯å¢ƒ**: æ€§èƒ½åŸºå‡†å’Œå‹åŠ›æµ‹è¯•
4. **ç”Ÿäº§æ¨¡æ‹Ÿ**: çœŸå®åœºæ™¯éªŒè¯

## å•å…ƒæµ‹è¯•

### åŠ¨æ€å¯¹è±¡è¿‡æ»¤å™¨æµ‹è¯•

```cpp
// æ–‡ä»¶ä½ç½®: ws_livox/src/localizer/test/test_dynamic_filter_comprehensive.cpp

#include <gtest/gtest.h>
#include <gmock/gmock.h>
#include "localizers/dynamic_object_filter.h"
#include <pcl/io/pcd_io.h>
#include <random>

class DynamicFilterComprehensiveTest : public ::testing::Test {
protected:
    void SetUp() override {
        // æ ‡å‡†é…ç½®
        config_.motion_threshold = 0.1f;
        config_.history_size = 5;
        config_.stability_threshold = 0.8f;
        config_.search_radius = 0.2f;

        filter_ = std::make_unique<localizers::DynamicObjectFilter>(config_);

        // è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡å¤æ€§
        rng_.seed(42);
    }

    localizers::DynamicFilterConfig config_;
    std::unique_ptr<localizers::DynamicObjectFilter> filter_;
    std::mt19937 rng_;

    // æµ‹è¯•è¾…åŠ©å‡½æ•°
    CloudType::Ptr createStaticScene(int num_points = 1000);
    CloudType::Ptr createDynamicScene(int frame_id, int num_static = 500, int num_dynamic = 100);
    CloudType::Ptr addNoise(const CloudType::Ptr& cloud, double noise_level = 0.01);
    void validateFilterRatio(double expected_ratio, double tolerance = 0.1);
};

CloudType::Ptr DynamicFilterComprehensiveTest::createStaticScene(int num_points) {
    CloudType::Ptr cloud(new CloudType);

    std::uniform_real_distribution<float> x_dist(-10.0f, 10.0f);
    std::uniform_real_distribution<float> y_dist(-10.0f, 10.0f);
    std::uniform_real_distribution<float> z_dist(0.0f, 3.0f);

    for (int i = 0; i < num_points; ++i) {
        PointType point;
        point.x = x_dist(rng_);
        point.y = y_dist(rng_);
        point.z = z_dist(rng_);
        point.intensity = 100.0f;
        cloud->push_back(point);
    }

    return cloud;
}

CloudType::Ptr DynamicFilterComprehensiveTest::createDynamicScene(
    int frame_id, int num_static, int num_dynamic) {

    CloudType::Ptr cloud(new CloudType);

    // é™æ€èƒŒæ™¯
    std::uniform_real_distribution<float> static_x(-5.0f, 5.0f);
    std::uniform_real_distribution<float> static_y(-5.0f, 5.0f);
    std::uniform_real_distribution<float> static_z(0.0f, 2.0f);

    for (int i = 0; i < num_static; ++i) {
        PointType point;
        point.x = static_x(rng_);
        point.y = static_y(rng_);
        point.z = static_z(rng_);
        point.intensity = 80.0f;
        cloud->push_back(point);
    }

    // åŠ¨æ€å¯¹è±¡ (éšæ—¶é—´ç§»åŠ¨)
    float dynamic_offset = frame_id * 0.2f; // æ¯å¸§ç§»åŠ¨0.2m
    std::uniform_real_distribution<float> dynamic_local(-0.5f, 0.5f);

    for (int i = 0; i < num_dynamic; ++i) {
        PointType point;
        point.x = 8.0f + dynamic_offset + dynamic_local(rng_);
        point.y = dynamic_local(rng_);
        point.z = 1.0f + dynamic_local(rng_) * 0.5f;
        point.intensity = 120.0f;
        cloud->push_back(point);
    }

    return cloud;
}

TEST_F(DynamicFilterComprehensiveTest, PureStaticScene) {
    // æµ‹è¯•çº¯é™æ€åœºæ™¯
    CloudType::Ptr static_cloud = createStaticScene(1000);

    // è¿ç»­è¾“å…¥ç›¸åŒé™æ€åœºæ™¯
    for (int frame = 0; frame < 10; ++frame) {
        auto filtered = filter_->filterDynamicObjects(static_cloud, frame * 0.1);

        if (frame >= config_.history_size) {
            // æœ‰è¶³å¤Ÿå†å²æ•°æ®åï¼Œå¤§éƒ¨åˆ†ç‚¹åº”è¯¥è¢«ä¿ç•™
            double retention_ratio = static_cast<double>(filtered->size()) / static_cloud->size();
            EXPECT_GT(retention_ratio, 0.85) << "Frame " << frame << " retention too low";
        }
    }

    auto stats = filter_->getLastFilterStats();
    EXPECT_LT(stats.filter_ratio, 0.15); // è¿‡æ»¤ç‡åº”è¯¥å¾ˆä½
}

TEST_F(DynamicFilterComprehensiveTest, MixedDynamicScene) {
    // æµ‹è¯•åŠ¨é™æ··åˆåœºæ™¯
    for (int frame = 0; frame < 15; ++frame) {
        CloudType::Ptr mixed_cloud = createDynamicScene(frame, 500, 100);
        auto filtered = filter_->filterDynamicObjects(mixed_cloud, frame * 0.1);

        if (frame >= config_.history_size) {
            auto stats = filter_->getLastFilterStats();

            // åº”è¯¥è¿‡æ»¤æ‰ä¸€äº›åŠ¨æ€ç‚¹
            EXPECT_GT(stats.filter_ratio, 0.05) << "Frame " << frame;
            EXPECT_LT(stats.filter_ratio, 0.5) << "Frame " << frame;

            // å¤§éƒ¨åˆ†é™æ€ç‚¹åº”è¯¥è¢«ä¿ç•™
            EXPECT_GT(filtered->size(), mixed_cloud->size() * 0.6) << "Frame " << frame;
        }
    }
}

TEST_F(DynamicFilterComprehensiveTest, NoiseRobustness) {
    // æµ‹è¯•å™ªå£°é²æ£’æ€§
    CloudType::Ptr base_cloud = createStaticScene(500);

    for (int frame = 0; frame < 8; ++frame) {
        CloudType::Ptr noisy_cloud = addNoise(base_cloud, 0.02); // 2cmå™ªå£°
        auto filtered = filter_->filterDynamicObjects(noisy_cloud, frame * 0.1);

        if (frame >= config_.history_size) {
            // å³ä½¿æœ‰å™ªå£°ï¼Œå¤§éƒ¨åˆ†é™æ€ç‚¹åº”è¯¥è¢«ä¿ç•™
            double retention_ratio = static_cast<double>(filtered->size()) / noisy_cloud->size();
            EXPECT_GT(retention_ratio, 0.7) << "Noise robustness failed at frame " << frame;
        }
    }
}

TEST_F(DynamicFilterComprehensiveTest, PerformanceBenchmark) {
    // æ€§èƒ½åŸºå‡†æµ‹è¯•
    CloudType::Ptr large_cloud = createStaticScene(50000); // å¤§ç‚¹äº‘

    auto start = std::chrono::high_resolution_clock::now();
    auto filtered = filter_->filterDynamicObjects(large_cloud, 0.0);
    auto end = std::chrono::high_resolution_clock::now();

    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);

    EXPECT_LT(duration.count(), 100) << "Processing too slow for large cloud";

    auto stats = filter_->getLastFilterStats();
    EXPECT_LT(stats.processing_time_ms, 100.0) << "Reported processing time inconsistent";
}

TEST_F(DynamicFilterComprehensiveTest, EdgeCases) {
    // è¾¹ç•Œæƒ…å†µæµ‹è¯•

    // ç©ºç‚¹äº‘
    CloudType::Ptr empty_cloud(new CloudType);
    auto filtered_empty = filter_->filterDynamicObjects(empty_cloud, 0.0);
    EXPECT_EQ(filtered_empty->size(), 0);

    // å•ç‚¹äº‘
    CloudType::Ptr single_point(new CloudType);
    PointType point;
    point.x = 1.0f;
    point.y = 2.0f;
    point.z = 3.0f;
    single_point->push_back(point);

    auto filtered_single = filter_->filterDynamicObjects(single_point, 0.0);
    EXPECT_EQ(filtered_single->size(), 1); // å•ç‚¹åº”è¯¥è¢«ä¿ç•™

    // å·¨å¤§æ—¶é—´è·³è·ƒ
    CloudType::Ptr normal_cloud = createStaticScene(100);
    filter_->filterDynamicObjects(normal_cloud, 0.0);
    auto filtered_jump = filter_->filterDynamicObjects(normal_cloud, 1000.0); // 1000ç§’å
    EXPECT_GT(filtered_jump->size(), normal_cloud->size() * 0.8); // åº”è¯¥é‡ç½®å†å²
}

// å‚æ•°åŒ–æµ‹è¯•
class DynamicFilterParameterTest : public DynamicFilterComprehensiveTest,
                                  public ::testing::WithParamInterface<std::tuple<float, int, float>> {
protected:
    void SetUp() override {
        auto params = GetParam();
        config_.motion_threshold = std::get<0>(params);
        config_.history_size = std::get<1>(params);
        config_.stability_threshold = std::get<2>(params);

        filter_ = std::make_unique<localizers::DynamicObjectFilter>(config_);
        rng_.seed(42);
    }
};

TEST_P(DynamicFilterParameterTest, ParameterSensitivity) {
    // æµ‹è¯•ä¸åŒå‚æ•°ç»„åˆçš„å½±å“
    for (int frame = 0; frame < 10; ++frame) {
        CloudType::Ptr cloud = createDynamicScene(frame, 300, 50);
        auto filtered = filter_->filterDynamicObjects(cloud, frame * 0.1);

        if (frame >= config_.history_size) {
            auto stats = filter_->getLastFilterStats();

            // åŸºæœ¬æ€§èƒ½è¦æ±‚
            EXPECT_LT(stats.processing_time_ms, 200.0);
            EXPECT_GT(filtered->size(), cloud->size() * 0.3);
            EXPECT_LT(filtered->size(), cloud->size() * 1.0);
        }
    }
}

INSTANTIATE_TEST_SUITE_P(
    ParameterVariations,
    DynamicFilterParameterTest,
    ::testing::Values(
        std::make_tuple(0.05f, 3, 0.7f),  // æ•æ„Ÿè®¾ç½®
        std::make_tuple(0.1f, 5, 0.8f),   // æ ‡å‡†è®¾ç½®
        std::make_tuple(0.2f, 7, 0.9f)    // ä¿å®ˆè®¾ç½®
    )
);
```

### PGOå›ç¯æ£€æµ‹æµ‹è¯•

```cpp
// æ–‡ä»¶ä½ç½®: ws_livox/src/pgo/test/test_advanced_loop_detector_comprehensive.cpp

#include <gtest/gtest.h>
#include <gmock/gmock.h>
#include "pgos/advanced_loop_detector.h"
#include <pcl/io/pcd_io.h>

class AdvancedLoopDetectorComprehensiveTest : public ::testing::Test {
protected:
    void SetUp() override {
        config_.candidate_search_radius = 10.0;
        config_.min_time_separation = 5.0;
        config_.min_confidence_score = 0.7;
        config_.feature_radius = 0.5;

        detector_ = std::make_unique<pgos::AdvancedLoopDetector>(config_);
    }

    pgos::AdvancedLoopConfig config_;
    std::unique_ptr<pgos::AdvancedLoopDetector> detector_;

    // æµ‹è¯•è¾…åŠ©å‡½æ•°
    std::vector<pgos::KeyPoseWithCloud> createLinearTrajectory(int num_poses, double spacing = 1.0);
    std::vector<pgos::KeyPoseWithCloud> createLoopTrajectory(int num_poses, double radius = 10.0);
    pgos::KeyPoseWithCloud createSimilarFrame(const pgos::KeyPoseWithCloud& reference, double noise_level = 0.1);
};

std::vector<pgos::KeyPoseWithCloud> AdvancedLoopDetectorComprehensiveTest::createLinearTrajectory(
    int num_poses, double spacing) {

    std::vector<pgos::KeyPoseWithCloud> trajectory;

    for (int i = 0; i < num_poses; ++i) {
        pgos::KeyPoseWithCloud pose;
        pose.t_global = Eigen::Vector3d(i * spacing, 0, 0);
        pose.r_global = Eigen::Matrix3d::Identity();
        pose.timestamp = i * 1.0;

        // åˆ›å»ºç‰¹å¾ä¸°å¯Œçš„ç‚¹äº‘
        pose.body_cloud = std::make_shared<CloudType>();
        for (int j = 0; j < 500; ++j) {
            PointType point;
            point.x = (j % 20) * 0.1f - 1.0f;
            point.y = (j / 20) * 0.1f - 1.0f;
            point.z = std::sin(j * 0.1f) * 0.5f;
            point.intensity = 100.0f + j % 50;
            pose.body_cloud->push_back(point);
        }

        trajectory.push_back(pose);
    }

    return trajectory;
}

std::vector<pgos::KeyPoseWithCloud> AdvancedLoopDetectorComprehensiveTest::createLoopTrajectory(
    int num_poses, double radius) {

    std::vector<pgos::KeyPoseWithCloud> trajectory;

    for (int i = 0; i < num_poses; ++i) {
        double angle = 2.0 * M_PI * i / num_poses;

        pgos::KeyPoseWithCloud pose;
        pose.t_global = Eigen::Vector3d(radius * cos(angle), radius * sin(angle), 0);

        // æœå‘åœ†å¿ƒ
        Eigen::Vector3d forward(-cos(angle), -sin(angle), 0);
        Eigen::Vector3d up(0, 0, 1);
        Eigen::Vector3d right = forward.cross(up);

        pose.r_global.col(0) = forward;
        pose.r_global.col(1) = right;
        pose.r_global.col(2) = up;

        pose.timestamp = i * 2.0; // ç¡®ä¿æ—¶é—´é—´éš”è¶³å¤Ÿ

        // åˆ›å»ºä¸ä½ç½®ç›¸å…³çš„ç‚¹äº‘
        pose.body_cloud = std::make_shared<CloudType>();
        for (int j = 0; j < 1000; ++j) {
            PointType point;
            point.x = (j % 30) * 0.1f - 1.5f;
            point.y = (j / 30) * 0.1f - 1.5f;
            point.z = abs(j % 10) * 0.1f;

            // æ·»åŠ ä½ç½®ç›¸å…³çš„ç‰¹å¾
            point.intensity = 100.0f + (int)(angle * 10) % 100;
            pose.body_cloud->push_back(point);
        }

        trajectory.push_back(pose);
    }

    return trajectory;
}

TEST_F(AdvancedLoopDetectorComprehensiveTest, NoFalsePositivesLinear) {
    // æµ‹è¯•çº¿æ€§è½¨è¿¹ä¸åº”è¯¥äº§ç”Ÿå›ç¯
    auto trajectory = createLinearTrajectory(20, 2.0);

    for (size_t i = 10; i < trajectory.size(); ++i) {
        auto candidates = detector_->detectLoopCandidates(trajectory, i);

        // çº¿æ€§è½¨è¿¹ä¸åº”è¯¥æœ‰å›ç¯
        EXPECT_TRUE(candidates.empty())
            << "False positive detected at pose " << i;
    }

    auto stats = detector_->getDetectionStats();
    EXPECT_EQ(stats.successful_detections, 0);
    EXPECT_GT(stats.total_queries, 0);
}

TEST_F(AdvancedLoopDetectorComprehensiveTest, DetectTrueLoops) {
    // æµ‹è¯•ç¯å½¢è½¨è¿¹åº”è¯¥æ£€æµ‹åˆ°å›ç¯
    auto trajectory = createLoopTrajectory(20, 5.0);

    size_t loop_detections = 0;

    // ä»è½¨è¿¹ååŠæ®µå¼€å§‹æ£€æµ‹
    for (size_t i = 15; i < trajectory.size(); ++i) {
        auto candidates = detector_->detectLoopCandidates(trajectory, i);

        for (const auto& candidate : candidates) {
            if (candidate.is_verified && candidate.combined_score >= config_.min_confidence_score) {
                loop_detections++;

                // éªŒè¯å›ç¯æ£€æµ‹çš„åˆç†æ€§
                EXPECT_LT(candidate.candidate_idx, i - 10)
                    << "Loop detected too close in time";
                EXPECT_GT(candidate.combined_score, config_.min_confidence_score)
                    << "Loop confidence too low";

                // éªŒè¯å˜æ¢çŸ©é˜µçš„åˆç†æ€§
                Eigen::Vector3f translation = candidate.transform.block<3, 1>(0, 3);
                EXPECT_LT(translation.norm(), 5.0)
                    << "Loop closure transform too large";
            }
        }
    }

    EXPECT_GT(loop_detections, 0) << "No loops detected in circular trajectory";

    auto stats = detector_->getDetectionStats();
    EXPECT_GT(stats.successful_detections, 0);
    EXPECT_GT(stats.recall_rate, 0.5); // è‡³å°‘50%å¬å›ç‡
}

TEST_F(AdvancedLoopDetectorComprehensiveTest, PerformanceBenchmark) {
    // æ€§èƒ½åŸºå‡†æµ‹è¯•
    auto large_trajectory = createLinearTrajectory(1000, 1.0);

    auto start = std::chrono::high_resolution_clock::now();

    for (size_t i = 100; i < 110; ++i) { // æµ‹è¯•10æ¬¡æ£€æµ‹
        detector_->detectLoopCandidates(large_trajectory, i);
    }

    auto end = std::chrono::high_resolution_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);

    // å¹³å‡æ¯æ¬¡æ£€æµ‹åº”è¯¥åœ¨100mså†…
    double avg_time = duration.count() / 10.0;
    EXPECT_LT(avg_time, 100.0) << "Loop detection too slow: " << avg_time << "ms";

    auto stats = detector_->getDetectionStats();
    EXPECT_LT(stats.average_detection_time_ms, 100.0);
}

TEST_F(AdvancedLoopDetectorComprehensiveTest, RobustnessToNoise) {
    // æµ‹è¯•å¯¹å™ªå£°çš„é²æ£’æ€§
    auto trajectory = createLoopTrajectory(15, 8.0);

    // æ·»åŠ å™ªå£°åˆ°æœ€åå‡ å¸§
    for (size_t i = 12; i < trajectory.size(); ++i) {
        // ä½ç½®å™ªå£°
        trajectory[i].t_global += Eigen::Vector3d::Random() * 0.1;

        // ç‚¹äº‘å™ªå£°
        for (auto& point : trajectory[i].body_cloud->points) {
            point.x += (rand() % 21 - 10) * 0.01f; // Â±10cmå™ªå£°
            point.y += (rand() % 21 - 10) * 0.01f;
            point.z += (rand() % 11 - 5) * 0.01f;  // Â±5cmå™ªå£°
        }
    }

    size_t robust_detections = 0;

    for (size_t i = 12; i < trajectory.size(); ++i) {
        auto candidates = detector_->detectLoopCandidates(trajectory, i);

        for (const auto& candidate : candidates) {
            if (candidate.is_verified && candidate.combined_score >= config_.min_confidence_score * 0.8) {
                robust_detections++;
            }
        }
    }

    // å³ä½¿æœ‰å™ªå£°ï¼Œä¹Ÿåº”è¯¥èƒ½æ£€æµ‹åˆ°ä¸€äº›å›ç¯
    EXPECT_GT(robust_detections, 0) << "Not robust to noise";
}

TEST_F(AdvancedLoopDetectorComprehensiveTest, ConfigurationSensitivity) {
    // æµ‹è¯•é…ç½®å‚æ•°æ•æ„Ÿæ€§
    auto trajectory = createLoopTrajectory(12, 6.0);

    // æµ‹è¯•ä¸åŒç½®ä¿¡åº¦é˜ˆå€¼
    std::vector<double> confidence_thresholds = {0.5, 0.7, 0.9};

    for (double threshold : confidence_thresholds) {
        config_.min_confidence_score = threshold;
        detector_->updateConfig(config_);

        size_t detections = 0;
        for (size_t i = 8; i < trajectory.size(); ++i) {
            auto candidates = detector_->detectLoopCandidates(trajectory, i);
            detections += candidates.size();
        }

        if (threshold <= 0.7) {
            EXPECT_GT(detections, 0) << "No detections with threshold " << threshold;
        }
        // è¾ƒé«˜é˜ˆå€¼å¯èƒ½æ²¡æœ‰æ£€æµ‹ç»“æœï¼Œè¿™æ˜¯æ­£å¸¸çš„
    }
}

// å‹åŠ›æµ‹è¯•
TEST_F(AdvancedLoopDetectorComprehensiveTest, StressTest) {
    // å¤§è§„æ¨¡è½¨è¿¹å‹åŠ›æµ‹è¯•
    auto large_trajectory = createLoopTrajectory(200, 20.0);

    size_t total_detections = 0;
    double total_time = 0.0;

    for (size_t i = 150; i < large_trajectory.size(); i += 5) { // æ¯5å¸§æ£€æµ‹ä¸€æ¬¡
        auto start = std::chrono::high_resolution_clock::now();
        auto candidates = detector_->detectLoopCandidates(large_trajectory, i);
        auto end = std::chrono::high_resolution_clock::now();

        auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end - start);
        total_time += duration.count() / 1000.0; // è½¬æ¢ä¸ºæ¯«ç§’

        total_detections += candidates.size();
    }

    // æ€§èƒ½è¦æ±‚
    double avg_time = total_time / 10.0; // 10æ¬¡æ£€æµ‹
    EXPECT_LT(avg_time, 200.0) << "Average detection time too high under stress";

    // åŠŸèƒ½è¦æ±‚
    EXPECT_GT(total_detections, 0) << "No detections in large trajectory";

    auto stats = detector_->getDetectionStats();
    EXPECT_LT(stats.false_positives, stats.successful_detections * 0.1)
        << "Too many false positives";
}
```

### HBAå®æ—¶ä¼˜åŒ–æµ‹è¯•

```cpp
// æ–‡ä»¶ä½ç½®: ws_livox/src/hba/test/test_realtime_hba_comprehensive.cpp

#include <gtest/gtest.h>
#include <gmock/gmock.h>
#include "hba/realtime_hba.h"
#include <thread>
#include <atomic>

class RealtimeHBAComprehensiveTest : public ::testing::Test {
protected:
    void SetUp() override {
        config_.target_frequency = 10.0;
        config_.max_window_size = 10;
        config_.num_optimization_threads = 2;
        config_.enable_adaptive_scheduling = true;

        realtime_hba_ = std::make_unique<hba::RealtimeHBA>(config_);
    }

    void TearDown() override {
        if (realtime_hba_->isRunning()) {
            realtime_hba_->stop();
        }
    }

    hba::RealtimeHBAConfig config_;
    std::unique_ptr<hba::RealtimeHBA> realtime_hba_;

    // æµ‹è¯•è¾…åŠ©å‡½æ•°
    hba::KeyPoseWithCloud createTestFrame(int frame_id, const Eigen::Vector3d& position);
    void generateTestTrajectory(int num_frames, double frame_interval = 0.1);
    void waitForOptimizations(int expected_optimizations, int timeout_ms = 5000);
};

hba::KeyPoseWithCloud RealtimeHBAComprehensiveTest::createTestFrame(
    int frame_id, const Eigen::Vector3d& position) {

    hba::KeyPoseWithCloud frame;
    frame.timestamp = frame_id * 0.1;
    frame.t_global = position;
    frame.r_global = Eigen::Matrix3d::Identity();

    // åˆ›å»ºæµ‹è¯•ç‚¹äº‘
    frame.body_cloud = std::make_shared<CloudType>();
    for (int i = 0; i < 1000; ++i) {
        PointType point;
        point.x = (i % 20) * 0.05f - 0.5f;
        point.y = (i / 20) * 0.05f - 0.5f;
        point.z = abs(i % 10) * 0.02f;
        point.intensity = 100.0f + frame_id % 50;
        frame.body_cloud->push_back(point);
    }

    return frame;
}

void RealtimeHBAComprehensiveTest::generateTestTrajectory(int num_frames, double frame_interval) {
    ASSERT_TRUE(realtime_hba_->start()) << "Failed to start realtime HBA";

    for (int i = 0; i < num_frames; ++i) {
        Eigen::Vector3d position(i * 0.1, 0, 0); // ç›´çº¿è½¨è¿¹
        auto frame = createTestFrame(i, position);

        ASSERT_TRUE(realtime_hba_->addFrameAsync(frame)) << "Failed to add frame " << i;

        std::this_thread::sleep_for(std::chrono::duration<double>(frame_interval));
    }
}

void RealtimeHBAComprehensiveTest::waitForOptimizations(int expected_optimizations, int timeout_ms) {
    auto start_time = std::chrono::steady_clock::now();

    while (std::chrono::steady_clock::now() - start_time < std::chrono::milliseconds(timeout_ms)) {
        auto stats = realtime_hba_->getPerformanceStats();
        if (stats.successful_optimizations >= static_cast<size_t>(expected_optimizations)) {
            return;
        }
        std::this_thread::sleep_for(std::chrono::milliseconds(10));
    }

    FAIL() << "Timeout waiting for optimizations";
}

TEST_F(RealtimeHBAComprehensiveTest, BasicFunctionality) {
    // åŸºæœ¬åŠŸèƒ½æµ‹è¯•
    ASSERT_TRUE(realtime_hba_->start());
    EXPECT_TRUE(realtime_hba_->isRunning());

    // æ·»åŠ ä¸€äº›æµ‹è¯•å¸§
    for (int i = 0; i < 20; ++i) {
        auto frame = createTestFrame(i, Eigen::Vector3d(i * 0.1, 0, 0));
        EXPECT_TRUE(realtime_hba_->addFrameAsync(frame));
    }

    // ç­‰å¾…ä¸€äº›ä¼˜åŒ–å®Œæˆ
    std::this_thread::sleep_for(std::chrono::seconds(2));

    auto stats = realtime_hba_->getPerformanceStats();
    EXPECT_GT(stats.total_frames, 15);
    EXPECT_GT(stats.successful_optimizations, 0);

    realtime_hba_->stop();
    EXPECT_FALSE(realtime_hba_->isRunning());
}

TEST_F(RealtimeHBAComprehensiveTest, PerformanceTargets) {
    // æ€§èƒ½ç›®æ ‡æµ‹è¯•
    generateTestTrajectory(100, 0.05); // 20Hzè¾“å…¥

    // ç­‰å¾…è¶³å¤Ÿçš„ä¼˜åŒ–
    waitForOptimizations(5, 10000);

    auto stats = realtime_hba_->getPerformanceStats();

    // æ£€æŸ¥é¢‘ç‡ç›®æ ‡
    EXPECT_GT(stats.current_frequency, config_.target_frequency * 0.7)
        << "Frequency too low: " << stats.current_frequency;

    // æ£€æŸ¥å¤„ç†æ—¶é—´
    EXPECT_LT(stats.average_optimization_time_ms, 100.0)
        << "Average optimization time too high: " << stats.average_optimization_time_ms;

    // æ£€æŸ¥æˆåŠŸç‡
    double success_rate = static_cast<double>(stats.successful_optimizations) /
                         (stats.successful_optimizations + stats.failed_optimizations);
    EXPECT_GT(success_rate, 0.8) << "Success rate too low: " << success_rate;
}

TEST_F(RealtimeHBAComprehensiveTest, AdaptiveScheduling) {
    // è‡ªé€‚åº”è°ƒåº¦æµ‹è¯•
    config_.enable_adaptive_scheduling = true;
    config_.max_optimization_time_ms = 50.0; // è¾ƒä¸¥æ ¼çš„æ—¶é—´é™åˆ¶
    realtime_hba_->updateConfig(config_);

    ASSERT_TRUE(realtime_hba_->start());

    // ç¬¬ä¸€é˜¶æ®µï¼šæ­£å¸¸è´Ÿè½½
    for (int i = 0; i < 30; ++i) {
        auto frame = createTestFrame(i, Eigen::Vector3d(i * 0.1, 0, 0));
        realtime_hba_->addFrameAsync(frame);
        std::this_thread::sleep_for(std::chrono::milliseconds(100)); // 10Hz
    }

    std::this_thread::sleep_for(std::chrono::seconds(1));
    auto normal_stats = realtime_hba_->getPerformanceStats();

    // ç¬¬äºŒé˜¶æ®µï¼šé«˜è´Ÿè½½
    for (int i = 30; i < 100; ++i) {
        auto frame = createTestFrame(i, Eigen::Vector3d(i * 0.1, 0, 0));
        realtime_hba_->addFrameAsync(frame);
        std::this_thread::sleep_for(std::chrono::milliseconds(20)); // 50Hz
    }

    std::this_thread::sleep_for(std::chrono::seconds(2));
    auto high_load_stats = realtime_hba_->getPerformanceStats();

    // è‡ªé€‚åº”è°ƒåº¦åº”è¯¥èƒ½å¤Ÿå¤„ç†è´Ÿè½½å˜åŒ–
    EXPECT_LT(high_load_stats.queue_length, 15)
        << "Queue not managed under high load";
    EXPECT_GT(high_load_stats.successful_optimizations, normal_stats.successful_optimizations)
        << "No additional optimizations under high load";
}

TEST_F(RealtimeHBAComprehensiveTest, ConcurrencyStressTest) {
    // å¹¶å‘å‹åŠ›æµ‹è¯•
    ASSERT_TRUE(realtime_hba_->start());

    std::atomic<int> frames_added{0};
    std::atomic<bool> stop_flag{false};

    // å¤šä¸ªçº¿ç¨‹åŒæ—¶æ·»åŠ å¸§
    std::vector<std::thread> producer_threads;

    for (int t = 0; t < 3; ++t) {
        producer_threads.emplace_back([this, &frames_added, &stop_flag, t]() {
            int frame_id = t * 1000;
            while (!stop_flag) {
                auto frame = createTestFrame(frame_id++,
                    Eigen::Vector3d(frame_id * 0.05, t * 2.0, 0));

                if (realtime_hba_->addFrameAsync(frame)) {
                    frames_added++;
                }

                std::this_thread::sleep_for(std::chrono::milliseconds(50));
            }
        });
    }

    // è¿è¡Œ5ç§’
    std::this_thread::sleep_for(std::chrono::seconds(5));
    stop_flag = true;

    for (auto& thread : producer_threads) {
        thread.join();
    }

    // ç­‰å¾…å¤„ç†å®Œæˆ
    std::this_thread::sleep_for(std::chrono::seconds(2));

    auto stats = realtime_hba_->getPerformanceStats();

    EXPECT_GT(frames_added.load(), 200) << "Not enough frames added";
    EXPECT_GT(stats.successful_optimizations, 10) << "Not enough optimizations";
    EXPECT_LT(stats.failed_optimizations, stats.successful_optimizations * 0.2)
        << "Too many failures under stress";
}

TEST_F(RealtimeHBAComprehensiveTest, MemoryStability) {
    // å†…å­˜ç¨³å®šæ€§æµ‹è¯•
    ASSERT_TRUE(realtime_hba_->start());

    size_t initial_memory = getCurrentMemoryUsage();

    // é•¿æ—¶é—´è¿è¡Œ
    for (int batch = 0; batch < 20; ++batch) {
        for (int i = 0; i < 50; ++i) {
            auto frame = createTestFrame(batch * 50 + i,
                Eigen::Vector3d(i * 0.1, batch * 5.0, 0));
            realtime_hba_->addFrameAsync(frame);
        }

        std::this_thread::sleep_for(std::chrono::milliseconds(500));

        // æ¯ä¸ªæ‰¹æ¬¡åæ£€æŸ¥å†…å­˜
        if (batch % 5 == 0) {
            size_t current_memory = getCurrentMemoryUsage();
            double memory_growth = static_cast<double>(current_memory - initial_memory) / initial_memory;

            EXPECT_LT(memory_growth, 2.0)
                << "Memory growth too high: " << memory_growth * 100 << "%";
        }
    }

    auto final_stats = realtime_hba_->getPerformanceStats();
    EXPECT_GT(final_stats.successful_optimizations, 50);
}

TEST_F(RealtimeHBAComprehensiveTest, QualityValidation) {
    // ä¼˜åŒ–è´¨é‡éªŒè¯
    ASSERT_TRUE(realtime_hba_->start());

    // åˆ›å»ºæœ‰ç´¯ç§¯è¯¯å·®çš„è½¨è¿¹
    std::vector<Eigen::Vector3d> noisy_trajectory;
    Eigen::Vector3d position(0, 0, 0);

    for (int i = 0; i < 50; ++i) {
        // æ·»åŠ ç´¯ç§¯è¯¯å·®
        Eigen::Vector3d noise = Eigen::Vector3d::Random() * 0.01;
        position += Eigen::Vector3d(0.1, 0, 0) + noise;
        noisy_trajectory.push_back(position);

        auto frame = createTestFrame(i, position);
        realtime_hba_->addFrameAsync(frame);

        std::this_thread::sleep_for(std::chrono::milliseconds(100));
    }

    // ç­‰å¾…ä¼˜åŒ–å®Œæˆ
    std::this_thread::sleep_for(std::chrono::seconds(3));

    auto optimized_poses = realtime_hba_->getOptimizedPoses();
    ASSERT_GT(optimized_poses.size(), 30);

    // æ£€æŸ¥ä¼˜åŒ–åçš„è½¨è¿¹æ˜¯å¦æ›´å¹³æ»‘
    double original_roughness = 0.0;
    double optimized_roughness = 0.0;

    for (size_t i = 1; i < std::min(noisy_trajectory.size(), optimized_poses.size()) - 1; ++i) {
        // è®¡ç®—åŸè½¨è¿¹çš„ç²—ç³™åº¦ï¼ˆäºŒé˜¶å·®åˆ†ï¼‰
        Eigen::Vector3d orig_accel = noisy_trajectory[i+1] - 2*noisy_trajectory[i] + noisy_trajectory[i-1];
        original_roughness += orig_accel.norm();

        // è®¡ç®—ä¼˜åŒ–åè½¨è¿¹çš„ç²—ç³™åº¦
        Eigen::Vector3d opt_accel = optimized_poses[i+1].t - 2*optimized_poses[i].t + optimized_poses[i-1].t;
        optimized_roughness += opt_accel.norm();
    }

    EXPECT_LT(optimized_roughness, original_roughness * 0.8)
        << "Optimization did not improve trajectory smoothness";
}

// è¾…åŠ©å‡½æ•°å®ç°
size_t RealtimeHBAComprehensiveTest::getCurrentMemoryUsage() {
    std::ifstream status_file("/proc/self/status");
    std::string line;
    while (std::getline(status_file, line)) {
        if (line.substr(0, 6) == "VmRSS:") {
            std::istringstream iss(line);
            std::string label, value, unit;
            iss >> label >> value >> unit;
            return std::stoul(value) * 1024;
        }
    }
    return 0;
}
```

## é›†æˆæµ‹è¯•

### ç³»ç»Ÿçº§é›†æˆæµ‹è¯•

```cpp
// æ–‡ä»¶ä½ç½®: test/integration/test_slam_system_integration.cpp

#include <gtest/gtest.h>
#include <rclcpp/rclcpp.hpp>
#include <sensor_msgs/msg/point_cloud2.hpp>
#include <nav_msgs/msg/odometry.hpp>
#include <rosbag2_cpp/reader.hpp>

class SLAMSystemIntegrationTest : public ::testing::Test {
protected:
    void SetUp() override {
        rclcpp::init(0, nullptr);

        // å¯åŠ¨æ‰€æœ‰SLAMç»„ä»¶
        startSLAMSystem();

        // ç­‰å¾…ç³»ç»Ÿåˆå§‹åŒ–
        std::this_thread::sleep_for(std::chrono::seconds(3));
    }

    void TearDown() override {
        stopSLAMSystem();
        rclcpp::shutdown();
    }

    void startSLAMSystem();
    void stopSLAMSystem();
    void playTestBag(const std::string& bag_path);
    void validateSystemOutput();

    std::vector<rclcpp::Node::SharedPtr> nodes_;
    std::map<std::string, std::vector<std::string>> topic_messages_;
};

void SLAMSystemIntegrationTest::startSLAMSystem() {
    // è¿™é‡Œä¼šå¯åŠ¨å®é™…çš„ROS2èŠ‚ç‚¹
    // å®é™…å®ç°ä¸­å¯èƒ½éœ€è¦ä½¿ç”¨launchæ–‡ä»¶æˆ–ç›´æ¥åˆ›å»ºèŠ‚ç‚¹
}

TEST_F(SLAMSystemIntegrationTest, EndToEndDataFlow) {
    // ç«¯åˆ°ç«¯æ•°æ®æµæµ‹è¯•
    playTestBag("test_data/integration_test.bag");

    // éªŒè¯å„ä¸ªç»„ä»¶çš„è¾“å‡º
    validateSystemOutput();

    // æ£€æŸ¥å…³é”®è¯é¢˜æ˜¯å¦æœ‰æ•°æ®
    EXPECT_GT(topic_messages_["/fastlio2/lio_odom"].size(), 100);
    EXPECT_GT(topic_messages_["/pgo/loop_markers"].size(), 1);
    EXPECT_GT(topic_messages_["/hba/optimized_map"].size(), 10);
    EXPECT_GT(topic_messages_["/localizer/filtered_cloud"].size(), 100);
}

TEST_F(SLAMSystemIntegrationTest, SystemResilience) {
    // ç³»ç»Ÿå¼¹æ€§æµ‹è¯•ï¼šæ¨¡æ‹Ÿå„ç§æ•…éšœæƒ…å†µ

    // 1. æ•°æ®ä¸­æ–­æµ‹è¯•
    playTestBag("test_data/data_interruption_test.bag");
    validateSystemOutput();

    // 2. é«˜é¢‘æ•°æ®æµ‹è¯•
    playTestBag("test_data/high_frequency_test.bag");
    validateSystemOutput();

    // 3. å™ªå£°æ•°æ®æµ‹è¯•
    playTestBag("test_data/noisy_data_test.bag");
    validateSystemOutput();
}

TEST_F(SLAMSystemIntegrationTest, PerformanceUnderLoad) {
    // è´Ÿè½½ä¸‹çš„æ€§èƒ½æµ‹è¯•
    auto start_time = std::chrono::steady_clock::now();

    playTestBag("test_data/performance_test.bag");

    auto end_time = std::chrono::steady_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::seconds>(end_time - start_time);

    // æ£€æŸ¥å®æ—¶æ€§èƒ½
    EXPECT_LT(duration.count(), 300); // 5åˆ†é’Ÿæ•°æ®åº”è¯¥åœ¨5åˆ†é’Ÿå†…å¤„ç†å®Œ

    validateSystemOutput();
}
```

### æ€§èƒ½é›†æˆæµ‹è¯•è„šæœ¬

```bash
#!/bin/bash
# æ–‡ä»¶ä½ç½®: test/integration/performance_integration_test.sh

echo "Starting SLAM System Performance Integration Test..."

# è®¾ç½®æµ‹è¯•ç¯å¢ƒ
export ROS_DOMAIN_ID=42
export RCUTILS_LOGGING_LEVEL=WARN

cd ws_livox
source install/setup.bash

# 1. å¯åŠ¨å®Œæ•´SLAMç³»ç»Ÿ
echo "Starting complete SLAM system..."

# FAST-LIO2
ros2 launch fastlio2 enhanced_visualization.launch.py \
    config_path:=$(pwd)/src/fastlio2/config/lio.yaml &
FASTLIO_PID=$!

sleep 3

# PGO with advanced loop detection
ros2 launch pgo pgo_launch.py \
    enable_advanced_loop_detection:=true &
PGO_PID=$!

sleep 2

# Realtime HBA
ros2 launch hba hba_launch.py \
    enable_realtime_mode:=true &
HBA_PID=$!

sleep 2

# Localizer with dynamic filter
ros2 launch localizer localizer_launch.py \
    enable_dynamic_filter:=true &
LOCALIZER_PID=$!

sleep 3

echo "All components started. Running performance tests..."

# 2. æ€§èƒ½ç›‘æ§
monitor_performance() {
    local test_name=$1
    local duration=$2

    echo "Monitoring $test_name for $duration seconds..."

    # åˆ›å»ºç›‘æ§è„šæœ¬
    cat > /tmp/monitor_${test_name}.py << EOF
import rclpy
from rclcpp import Node
from std_msgs.msg import String
import time
import json

class PerformanceMonitor(Node):
    def __init__(self):
        super().__init__('performance_monitor')
        self.stats = {}

        # è®¢é˜…å„ç»„ä»¶æ€§èƒ½ç»Ÿè®¡
        self.create_subscription(String, '/hba/performance_stats',
                               lambda msg: self.record_stats('hba', msg), 10)
        self.create_subscription(String, '/localizer/dynamic_filter_stats',
                               lambda msg: self.record_stats('localizer', msg), 10)

        self.start_time = time.time()

    def record_stats(self, component, msg):
        if component not in self.stats:
            self.stats[component] = []
        self.stats[component].append({
            'timestamp': time.time() - self.start_time,
            'data': msg.data
        })

    def save_results(self):
        with open('/tmp/performance_${test_name}.json', 'w') as f:
            json.dump(self.stats, f, indent=2)

def main():
    rclpy.init()
    monitor = PerformanceMonitor()

    try:
        rclpy.spin_for_timeout(monitor, timeout_sec=$duration)
    finally:
        monitor.save_results()
        rclpy.shutdown()

if __name__ == '__main__':
    main()
EOF

    python3 /tmp/monitor_${test_name}.py &
    MONITOR_PID=$!

    sleep $duration
    kill $MONITOR_PID 2>/dev/null || true

    # åˆ†æç»“æœ
    if [ -f "/tmp/performance_${test_name}.json" ]; then
        echo "Performance results for $test_name:"
        python3 -c "
import json
with open('/tmp/performance_${test_name}.json') as f:
    data = json.load(f)

for component, stats in data.items():
    print(f'{component}: {len(stats)} measurements')
    if stats:
        print(f'  Duration: {stats[-1][\"timestamp\"]:.1f}s')
"
    fi
}

# 3. è¿è¡Œä¸åŒåœºæ™¯çš„æ€§èƒ½æµ‹è¯•

# åœºæ™¯1ï¼šå®¤å†…ç¯å¢ƒï¼ˆåŠ¨æ€å¯¹è±¡å¤šï¼‰
echo "Testing indoor scenario with dynamic objects..."
ros2 bag play ../test_data/indoor_dynamic_environment.bag --rate 1.0 &
BAG_PID=$!
monitor_performance "indoor" 120
kill $BAG_PID 2>/dev/null || true

sleep 5

# åœºæ™¯2ï¼šå®¤å¤–ç¯å¢ƒï¼ˆé•¿è·ç¦»å›ç¯ï¼‰
echo "Testing outdoor scenario with long-distance loops..."
ros2 bag play ../test_data/outdoor_loop_closure.bag --rate 1.0 &
BAG_PID=$!
monitor_performance "outdoor" 300
kill $BAG_PID 2>/dev/null || true

sleep 5

# åœºæ™¯3ï¼šé«˜é€Ÿåœºæ™¯ï¼ˆå®æ—¶æ€§æµ‹è¯•ï¼‰
echo "Testing high-speed scenario for real-time performance..."
ros2 bag play ../test_data/high_speed_trajectory.bag --rate 2.0 &
BAG_PID=$!
monitor_performance "high_speed" 180
kill $BAG_PID 2>/dev/null || true

# 4. æ€§èƒ½æŠ¥å‘Šç”Ÿæˆ
echo "Generating performance report..."

cat > /tmp/generate_report.py << 'EOF'
import json
import os
from datetime import datetime

def analyze_performance_data(test_name):
    file_path = f'/tmp/performance_{test_name}.json'
    if not os.path.exists(file_path):
        return None

    with open(file_path) as f:
        data = json.load(f)

    analysis = {
        'test_name': test_name,
        'components': {}
    }

    for component, stats in data.items():
        if not stats:
            continue

        component_analysis = {
            'total_measurements': len(stats),
            'duration': stats[-1]['timestamp'] if stats else 0,
            'avg_frequency': len(stats) / stats[-1]['timestamp'] if stats and stats[-1]['timestamp'] > 0 else 0
        }

        # è§£æHBAæ€§èƒ½æ•°æ®
        if component == 'hba':
            frequencies = []
            optimization_times = []

            for stat in stats:
                data_str = stat['data']
                if 'Freq=' in data_str:
                    freq = float(data_str.split('Freq=')[1].split('Hz')[0])
                    frequencies.append(freq)
                if 'AvgTime=' in data_str:
                    time_ms = float(data_str.split('AvgTime=')[1].split('ms')[0])
                    optimization_times.append(time_ms)

            if frequencies:
                component_analysis['avg_optimization_frequency'] = sum(frequencies) / len(frequencies)
                component_analysis['min_optimization_frequency'] = min(frequencies)

            if optimization_times:
                component_analysis['avg_optimization_time_ms'] = sum(optimization_times) / len(optimization_times)
                component_analysis['max_optimization_time_ms'] = max(optimization_times)

        analysis['components'][component] = component_analysis

    return analysis

def generate_report():
    report = {
        'test_timestamp': datetime.now().isoformat(),
        'scenarios': {}
    }

    for scenario in ['indoor', 'outdoor', 'high_speed']:
        analysis = analyze_performance_data(scenario)
        if analysis:
            report['scenarios'][scenario] = analysis

    # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶
    with open('/tmp/slam_performance_report.json', 'w') as f:
        json.dump(report, f, indent=2)

    # ç”Ÿæˆäººç±»å¯è¯»çš„æŠ¥å‘Š
    with open('/tmp/slam_performance_report.txt', 'w') as f:
        f.write("SLAM System Performance Integration Test Report\n")
        f.write("=" * 50 + "\n\n")
        f.write(f"Test Time: {report['test_timestamp']}\n\n")

        for scenario_name, scenario_data in report['scenarios'].items():
            f.write(f"Scenario: {scenario_name.upper()}\n")
            f.write("-" * 30 + "\n")

            for component, comp_data in scenario_data['components'].items():
                f.write(f"  {component.upper()}:\n")
                f.write(f"    Duration: {comp_data['duration']:.1f}s\n")
                f.write(f"    Measurements: {comp_data['total_measurements']}\n")
                f.write(f"    Frequency: {comp_data['avg_frequency']:.1f}Hz\n")

                if 'avg_optimization_frequency' in comp_data:
                    f.write(f"    Optimization Freq: {comp_data['avg_optimization_frequency']:.1f}Hz\n")
                if 'avg_optimization_time_ms' in comp_data:
                    f.write(f"    Avg Optimization Time: {comp_data['avg_optimization_time_ms']:.1f}ms\n")

                f.write("\n")
            f.write("\n")

    print("Performance report generated:")
    print("  JSON: /tmp/slam_performance_report.json")
    print("  Text: /tmp/slam_performance_report.txt")

if __name__ == '__main__':
    generate_report()
EOF

python3 /tmp/generate_report.py

# 5. æ¸…ç†
echo "Cleaning up..."
kill $FASTLIO_PID $PGO_PID $HBA_PID $LOCALIZER_PID 2>/dev/null || true

# 6. æ˜¾ç¤ºç»“æœ
echo "Performance Integration Test Results:"
echo "====================================="
cat /tmp/slam_performance_report.txt

# 7. éªŒè¯æ€§èƒ½æŒ‡æ ‡
echo "Validating performance metrics..."

python3 -c "
import json
import sys

with open('/tmp/slam_performance_report.json') as f:
    report = json.load(f)

exit_code = 0

for scenario, data in report['scenarios'].items():
    print(f'Validating {scenario}...')

    # æ£€æŸ¥HBAæ€§èƒ½
    if 'hba' in data['components']:
        hba_data = data['components']['hba']

        if 'avg_optimization_frequency' in hba_data:
            freq = hba_data['avg_optimization_frequency']
            if freq < 5.0:
                print(f'  âŒ HBA frequency too low: {freq:.1f}Hz < 5.0Hz')
                exit_code = 1
            else:
                print(f'  âœ… HBA frequency OK: {freq:.1f}Hz')

        if 'avg_optimization_time_ms' in hba_data:
            time_ms = hba_data['avg_optimization_time_ms']
            if time_ms > 100.0:
                print(f'  âŒ HBA optimization time too high: {time_ms:.1f}ms > 100ms')
                exit_code = 1
            else:
                print(f'  âœ… HBA optimization time OK: {time_ms:.1f}ms')

sys.exit(exit_code)
"

VALIDATION_RESULT=$?

if [ $VALIDATION_RESULT -eq 0 ]; then
    echo "âœ… All performance metrics passed!"
else
    echo "âŒ Some performance metrics failed!"
fi

echo "Performance integration test completed."
exit $VALIDATION_RESULT
```

## ç«¯åˆ°ç«¯æµ‹è¯•

### ç³»ç»Ÿçº§ç«¯åˆ°ç«¯æµ‹è¯•

```bash
#!/bin/bash
# æ–‡ä»¶ä½ç½®: test/e2e/end_to_end_system_test.sh

echo "Starting End-to-End SLAM System Test..."

# æµ‹è¯•é…ç½®
TEST_DATASETS_DIR="../test_data/e2e"
RESULTS_DIR="/tmp/e2e_test_results"
mkdir -p $RESULTS_DIR

cd ws_livox
source install/setup.bash

# ç«¯åˆ°ç«¯æµ‹è¯•å‡½æ•°
run_e2e_test() {
    local test_name=$1
    local dataset_path=$2
    local expected_performance=$3

    echo "Running E2E test: $test_name"
    echo "Dataset: $dataset_path"

    # åˆ›å»ºæµ‹è¯•ç»“æœç›®å½•
    local result_dir="$RESULTS_DIR/$test_name"
    mkdir -p $result_dir

    # å¯åŠ¨å®Œæ•´SLAMç³»ç»Ÿ
    echo "Starting SLAM system..."

    # ä½¿ç”¨é…ç½®åŒ–çš„å¯åŠ¨æ–¹å¼
    ros2 launch fastlio2 full_slam_system.launch.py \
        enable_dynamic_filter:=true \
        enable_advanced_pgo:=true \
        enable_realtime_hba:=true \
        output_dir:=$result_dir &
    SLAM_PID=$!

    sleep 5

    # å¯åŠ¨æ•°æ®è®°å½•
    echo "Starting data recording..."
    ros2 bag record -o $result_dir/output_bag \
        /fastlio2/lio_odom \
        /pgo/loop_markers \
        /hba/optimized_map \
        /localizer/filtered_cloud \
        /slam/performance_metrics &
    RECORD_PID=$!

    sleep 2

    # æ’­æ”¾æµ‹è¯•æ•°æ®
    echo "Playing test dataset..."
    local start_time=$(date +%s)

    ros2 bag play $dataset_path --rate 1.0
    local play_result=$?

    local end_time=$(date +%s)
    local duration=$((end_time - start_time))

    sleep 5  # ç­‰å¾…å¤„ç†å®Œæˆ

    # åœæ­¢è®°å½•å’ŒSLAMç³»ç»Ÿ
    kill $RECORD_PID 2>/dev/null || true
    kill $SLAM_PID 2>/dev/null || true

    sleep 3

    # åˆ†æç»“æœ
    echo "Analyzing results for $test_name..."

    local analysis_result=$(analyze_e2e_results $result_dir $expected_performance)

    echo "Test $test_name completed in ${duration}s"
    echo "Result: $analysis_result"

    return $play_result
}

# ç»“æœåˆ†æå‡½æ•°
analyze_e2e_results() {
    local result_dir=$1
    local expected_performance=$2

    # åˆ†æç”Ÿæˆçš„åœ°å›¾è´¨é‡
    python3 << EOF
import json
import numpy as np
from pathlib import Path

def analyze_results(result_dir, expected_perf):
    result_path = Path(result_dir)

    # åˆ†æè½¨è¿¹ç²¾åº¦
    trajectory_file = result_path / "trajectory.txt"
    if trajectory_file.exists():
        # è®¡ç®—è½¨è¿¹ç»Ÿè®¡
        print(f"Trajectory analysis completed")

    # åˆ†æåœ°å›¾è´¨é‡
    map_file = result_path / "final_map.pcd"
    if map_file.exists():
        print(f"Map quality analysis completed")

    # åˆ†ææ€§èƒ½æŒ‡æ ‡
    performance_file = result_path / "performance_summary.json"
    if performance_file.exists():
        with open(performance_file) as f:
            perf_data = json.load(f)

        # æ£€æŸ¥å…³é”®æ€§èƒ½æŒ‡æ ‡
        if perf_data.get('avg_processing_time_ms', 1000) < 100:
            print("âœ… Real-time performance: PASS")
        else:
            print("âŒ Real-time performance: FAIL")

        if perf_data.get('loop_closure_accuracy', 0) > 0.8:
            print("âœ… Loop closure accuracy: PASS")
        else:
            print("âŒ Loop closure accuracy: FAIL")

        if perf_data.get('dynamic_filter_effectiveness', 0) > 0.7:
            print("âœ… Dynamic filtering: PASS")
        else:
            print("âŒ Dynamic filtering: FAIL")

    return "ANALYSIS_COMPLETED"

print(analyze_results("$result_dir", "$expected_performance"))
EOF
}

# æµ‹è¯•åœºæ™¯å®šä¹‰
echo "Defining test scenarios..."

# åœºæ™¯1ï¼šå®¤å†…åŠ¨æ€ç¯å¢ƒ
echo "Test 1: Indoor Dynamic Environment"
run_e2e_test "indoor_dynamic" \
    "$TEST_DATASETS_DIR/indoor_with_people.bag" \
    "realtime_processing:100ms,dynamic_filter_ratio:0.2"

# åœºæ™¯2ï¼šå®¤å¤–å¤§å°ºåº¦å›ç¯
echo "Test 2: Outdoor Large-scale Loop Closure"
run_e2e_test "outdoor_loops" \
    "$TEST_DATASETS_DIR/outdoor_campus_loop.bag" \
    "loop_closure_accuracy:0.85,trajectory_error:0.5m"

# åœºæ™¯3ï¼šé«˜é€Ÿç§»åŠ¨åœºæ™¯
echo "Test 3: High-speed Movement"
run_e2e_test "high_speed" \
    "$TEST_DATASETS_DIR/drone_flight_path.bag" \
    "processing_frequency:10Hz,optimization_delay:50ms"

# åœºæ™¯4ï¼šå¤æ‚ç»“æ„åŒ–ç¯å¢ƒ
echo "Test 4: Complex Structured Environment"
run_e2e_test "structured_complex" \
    "$TEST_DATASETS_DIR/warehouse_navigation.bag" \
    "mapping_accuracy:0.1m,feature_matching:0.9"

# ç”Ÿæˆç»¼åˆæŠ¥å‘Š
echo "Generating comprehensive E2E report..."

cat > $RESULTS_DIR/e2e_summary_report.py << 'EOF'
import json
import os
from pathlib import Path
from datetime import datetime

def generate_e2e_report():
    results_dir = Path("/tmp/e2e_test_results")

    report = {
        'test_timestamp': datetime.now().isoformat(),
        'test_scenarios': {},
        'overall_summary': {
            'total_tests': 0,
            'passed_tests': 0,
            'failed_tests': 0
        }
    }

    # æ‰«ææµ‹è¯•ç»“æœç›®å½•
    for test_dir in results_dir.iterdir():
        if test_dir.is_dir() and test_dir.name != '.':
            test_name = test_dir.name

            # åˆ†ææ¯ä¸ªæµ‹è¯•çš„ç»“æœ
            scenario_report = analyze_scenario(test_dir)
            report['test_scenarios'][test_name] = scenario_report

            report['overall_summary']['total_tests'] += 1
            if scenario_report['status'] == 'PASSED':
                report['overall_summary']['passed_tests'] += 1
            else:
                report['overall_summary']['failed_tests'] += 1

    # ä¿å­˜æŠ¥å‘Š
    with open(results_dir / 'e2e_comprehensive_report.json', 'w') as f:
        json.dump(report, f, indent=2)

    # ç”Ÿæˆäººç±»å¯è¯»æŠ¥å‘Š
    generate_readable_report(report, results_dir / 'e2e_comprehensive_report.txt')

    return report

def analyze_scenario(test_dir):
    scenario_report = {
        'test_name': test_dir.name,
        'status': 'UNKNOWN',
        'metrics': {},
        'issues': []
    }

    # æ£€æŸ¥æ˜¯å¦æœ‰è¾“å‡ºæ–‡ä»¶
    output_bag = test_dir / 'output_bag'
    if not output_bag.exists():
        scenario_report['status'] = 'FAILED'
        scenario_report['issues'].append('No output bag recorded')
        return scenario_report

    # åˆ†ææ€§èƒ½æ•°æ®
    performance_file = test_dir / 'performance_summary.json'
    if performance_file.exists():
        try:
            with open(performance_file) as f:
                perf_data = json.load(f)
            scenario_report['metrics'] = perf_data
        except:
            scenario_report['issues'].append('Failed to read performance data')

    # åŸºäºæŒ‡æ ‡åˆ¤æ–­æµ‹è¯•çŠ¶æ€
    if len(scenario_report['issues']) == 0:
        scenario_report['status'] = 'PASSED'
    else:
        scenario_report['status'] = 'FAILED'

    return scenario_report

def generate_readable_report(report, output_file):
    with open(output_file, 'w') as f:
        f.write("SLAM System End-to-End Test Report\n")
        f.write("=" * 50 + "\n\n")
        f.write(f"Test Timestamp: {report['test_timestamp']}\n")
        f.write(f"Total Tests: {report['overall_summary']['total_tests']}\n")
        f.write(f"Passed: {report['overall_summary']['passed_tests']}\n")
        f.write(f"Failed: {report['overall_summary']['failed_tests']}\n\n")

        for test_name, test_data in report['test_scenarios'].items():
            f.write(f"Test: {test_name}\n")
            f.write("-" * 30 + "\n")
            f.write(f"Status: {test_data['status']}\n")

            if test_data['metrics']:
                f.write("Metrics:\n")
                for metric, value in test_data['metrics'].items():
                    f.write(f"  {metric}: {value}\n")

            if test_data['issues']:
                f.write("Issues:\n")
                for issue in test_data['issues']:
                    f.write(f"  - {issue}\n")

            f.write("\n")

if __name__ == '__main__':
    report = generate_e2e_report()

    print(f"E2E Test Summary:")
    print(f"Total: {report['overall_summary']['total_tests']}")
    print(f"Passed: {report['overall_summary']['passed_tests']}")
    print(f"Failed: {report['overall_summary']['failed_tests']}")

    if report['overall_summary']['failed_tests'] > 0:
        print("\nFailed tests:")
        for test_name, test_data in report['test_scenarios'].items():
            if test_data['status'] == 'FAILED':
                print(f"  - {test_name}: {', '.join(test_data['issues'])}")
EOF

python3 $RESULTS_DIR/e2e_summary_report.py

# æ˜¾ç¤ºæœ€ç»ˆç»“æœ
echo "End-to-End Test Results:"
echo "========================"
cat $RESULTS_DIR/e2e_comprehensive_report.txt

# æ£€æŸ¥æµ‹è¯•æ˜¯å¦é€šè¿‡
FINAL_RESULT=$(python3 -c "
import json
with open('$RESULTS_DIR/e2e_comprehensive_report.json') as f:
    report = json.load(f)
if report['overall_summary']['failed_tests'] == 0:
    print('PASSED')
else:
    print('FAILED')
")

echo "Final E2E Test Result: $FINAL_RESULT"

if [ "$FINAL_RESULT" = "PASSED" ]; then
    echo "ğŸ‰ All end-to-end tests passed successfully!"
    exit 0
else
    echo "âŒ Some end-to-end tests failed. Check the detailed report."
    exit 1
fi
```

## æŒç»­é›†æˆæµ‹è¯•

### CI/CDæµæ°´çº¿é…ç½®

```yaml
# æ–‡ä»¶ä½ç½®: .github/workflows/slam_comprehensive_test.yml
name: SLAM System Comprehensive Testing

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  unit-tests:
    runs-on: ubuntu-22.04
    strategy:
      matrix:
        ros-distro: [humble]

    steps:
    - uses: actions/checkout@v3

    - name: Setup ROS 2
      uses: ros-tooling/setup-ros@v0.6
      with:
        required-ros-distributions: ${{ matrix.ros-distro }}

    - name: Install Dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y \
          libpcl-dev \
          libeigen3-dev \
          libopencv-dev \
          libyaml-cpp-dev

    - name: Build SLAM System
      run: |
        cd ws_livox
        colcon build --cmake-args -DCMAKE_BUILD_TYPE=Release

    - name: Run Unit Tests
      run: |
        cd ws_livox
        source install/setup.bash
        colcon test --packages-select interface localizer pgo hba
        colcon test-result --verbose

    - name: Upload Test Results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: unit-test-results
        path: ws_livox/log/

  integration-tests:
    runs-on: ubuntu-22.04
    needs: unit-tests

    steps:
    - uses: actions/checkout@v3

    - name: Setup ROS 2
      uses: ros-tooling/setup-ros@v0.6
      with:
        required-ros-distributions: humble

    - name: Download Test Data
      run: |
        mkdir -p test_data
        # ä¸‹è½½æˆ–ç”Ÿæˆæµ‹è¯•æ•°æ®
        ./scripts/generate_test_data.sh

    - name: Build System
      run: |
        cd ws_livox
        colcon build --cmake-args -DCMAKE_BUILD_TYPE=Release

    - name: Run Integration Tests
      run: |
        cd ws_livox
        source install/setup.bash
        ../test/integration/performance_integration_test.sh

    - name: Upload Integration Results
      uses: actions/upload-artifact@v3
      with:
        name: integration-test-results
        path: /tmp/slam_performance_report.*

  performance-benchmarks:
    runs-on: ubuntu-22.04
    needs: integration-tests

    steps:
    - uses: actions/checkout@v3

    - name: Setup Performance Environment
      run: |
        # é…ç½®æ€§èƒ½æµ‹è¯•ç¯å¢ƒ
        sudo sysctl -w kernel.perf_event_paranoid=1
        sudo apt-get install -y linux-tools-generic

    - name: Run Performance Benchmarks
      run: |
        ./test/performance/run_benchmarks.sh

    - name: Generate Performance Report
      run: |
        python3 test/performance/generate_benchmark_report.py

    - name: Upload Performance Results
      uses: actions/upload-artifact@v3
      with:
        name: performance-benchmark-results
        path: test/performance/results/

  quality-assurance:
    runs-on: ubuntu-22.04

    steps:
    - uses: actions/checkout@v3

    - name: Code Quality Check
      run: |
        # é™æ€ä»£ç åˆ†æ
        find . -name "*.cpp" -o -name "*.hpp" | xargs cppcheck --enable=all

        # ä»£ç æ ¼å¼æ£€æŸ¥
        find . -name "*.cpp" -o -name "*.hpp" | xargs clang-format --dry-run --Werror

    - name: Documentation Check
      run: |
        # æ£€æŸ¥æ–‡æ¡£å®Œæ•´æ€§
        python3 scripts/check_documentation.py

    - name: Security Scan
      run: |
        # å®‰å…¨æ‰«æ
        bandit -r . -f json -o security_report.json || true

    - name: Upload QA Results
      uses: actions/upload-artifact@v3
      with:
        name: quality-assurance-results
        path: |
          security_report.json
          cppcheck_report.xml

  end-to-end-tests:
    runs-on: ubuntu-22.04
    needs: [unit-tests, integration-tests]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
    - uses: actions/checkout@v3

    - name: Setup Full Test Environment
      run: |
        # è®¾ç½®å®Œæ•´æµ‹è¯•ç¯å¢ƒ
        ./scripts/setup_e2e_environment.sh

    - name: Download E2E Test Data
      run: |
        # ä¸‹è½½å¤§å‹ç«¯åˆ°ç«¯æµ‹è¯•æ•°æ®é›†
        ./scripts/download_e2e_datasets.sh

    - name: Run End-to-End Tests
      run: |
        timeout 1800 ./test/e2e/end_to_end_system_test.sh

    - name: Upload E2E Results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: e2e-test-results
        path: /tmp/e2e_test_results/

  final-report:
    runs-on: ubuntu-22.04
    needs: [unit-tests, integration-tests, performance-benchmarks, quality-assurance]
    if: always()

    steps:
    - uses: actions/checkout@v3

    - name: Download All Artifacts
      uses: actions/download-artifact@v3

    - name: Generate Comprehensive Report
      run: |
        python3 scripts/generate_comprehensive_report.py \
          --unit-tests unit-test-results/ \
          --integration integration-test-results/ \
          --performance performance-benchmark-results/ \
          --quality quality-assurance-results/

    - name: Upload Final Report
      uses: actions/upload-artifact@v3
      with:
        name: comprehensive-test-report
        path: comprehensive_report.*

    - name: Comment on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const report = fs.readFileSync('comprehensive_report.md', 'utf8');

          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: report
          });
```

## æ€»ç»“

æœ¬æµ‹è¯•ä¸éªŒè¯æŒ‡å—æä¾›äº†å®Œæ•´çš„ä¸‰å±‚æµ‹è¯•æ¶æ„ï¼š

### æµ‹è¯•è¦†ç›–èŒƒå›´
- **å•å…ƒæµ‹è¯•**: è¦†ç›–æ ¸å¿ƒç®—æ³•å’Œç»„ä»¶
- **é›†æˆæµ‹è¯•**: éªŒè¯ç»„ä»¶é—´åä½œå’Œç³»ç»Ÿæ€§èƒ½
- **ç«¯åˆ°ç«¯æµ‹è¯•**: éªŒè¯å®Œæ•´ç³»ç»Ÿåœ¨çœŸå®åœºæ™¯ä¸‹çš„è¡¨ç°

### å…³é”®éªŒè¯æŒ‡æ ‡
- **åŠŸèƒ½æ­£ç¡®æ€§**: ç®—æ³•é€»è¾‘å’Œè¾“å‡ºæ­£ç¡®æ€§
- **æ€§èƒ½æŒ‡æ ‡**: å®æ—¶æ€§ã€ç²¾åº¦ã€èµ„æºä½¿ç”¨
- **é²æ£’æ€§**: å™ªå£°ã€å¼‚å¸¸æ•°æ®ã€ç³»ç»Ÿæ•…éšœçš„å¤„ç†
- **å¯æ‰©å±•æ€§**: å¤§è§„æ¨¡æ•°æ®å’Œé•¿æ—¶é—´è¿è¡Œçš„ç¨³å®šæ€§

### è´¨é‡ä¿è¯
- **è‡ªåŠ¨åŒ–æµ‹è¯•**: CI/CDæµæ°´çº¿ç¡®ä¿ä»£ç è´¨é‡
- **æ€§èƒ½åŸºå‡†**: æŒç»­ç›‘æ§ç³»ç»Ÿæ€§èƒ½é€€åŒ–
- **å›å½’æµ‹è¯•**: ç¡®ä¿æ–°åŠŸèƒ½ä¸å½±å“ç°æœ‰åŠŸèƒ½
- **æ–‡æ¡£éªŒè¯**: ç¡®ä¿æ–‡æ¡£ä¸å®é™…å®ç°ä¸€è‡´

é€šè¿‡æ‰§è¡Œè¿™å¥—å®Œæ•´çš„æµ‹è¯•æ–¹æ¡ˆï¼Œå¯ä»¥ç¡®ä¿ä¸‰å¤§åŠŸèƒ½å¢å¼ºï¼ˆåŠ¨æ€å¯¹è±¡å¤„ç†ã€PGOå›ç¯æ£€æµ‹ã€HBAå®æ—¶ä¼˜åŒ–ï¼‰çš„è´¨é‡å’Œå¯é æ€§ï¼Œä¸ºç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æä¾›ä¿¡å¿ƒä¿è¯ã€‚